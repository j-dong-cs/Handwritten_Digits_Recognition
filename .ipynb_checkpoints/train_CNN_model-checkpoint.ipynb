{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import os\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core import Dataset\n",
    "from azureml.core import Run # from utils import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Workspace from Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits_recognition\tcentralus\tmachinelearning\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuration from the config.json file in the config folder.\n",
    "ws = Workspace.from_config(path='jingjing.dong.mil/config/config.json')\n",
    "print(ws.name, ws.location, ws.resource_group, sep='\\t')\n",
    "compute_target = ws.compute_targets['cpucluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load \"MNIST Handwritten Digits\" Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.get_by_name(ws, name='MNIST_handwritten_digits').to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Column1', 'Column2', 'Column3', 'Column4', 'Column5', 'Column6',\n",
       "       'Column7', 'Column8', 'Column9', 'Column10',\n",
       "       ...\n",
       "       'Column776', 'Column777', 'Column778', 'Column779', 'Column780',\n",
       "       'Column781', 'Column782', 'Column783', 'Column784', 'Column785'],\n",
       "      dtype='object', length=785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Split Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the first row as the header\n",
    "new_header = dataset.iloc[0] #grab the first row for the header\n",
    "dataset = dataset[1:] #take the data less the header row\n",
    "dataset.columns = new_header #set the header row as the df header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      0,       1,       2,       3,       4,       5,       6,       7,\n",
       "             8,       9,\n",
       "       ...\n",
       "           775,     776,     777,     778,     779,     780,     781,     782,\n",
       "           783, 'label'],\n",
       "      dtype='object', name=0, length=785)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28 # all images in the training set is 28 X 28 greysacle\n",
    "num_classes = 10 # there are total 10 classes representing digits from 0 to 9\n",
    "\n",
    "def data_prep(data):\n",
    "    # convert the labels in data to dummy variable columns 0 .. 9\n",
    "    out_y = keras.utils.to_categorical(data.label, num_classes)\n",
    "    \n",
    "    num_images = data.shape[0]\n",
    "    x_as_array = data.values[:,:784] # label is at column 784\n",
    "    x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = x_shaped_array / 255.0 # normalize data to be in the range of 0 to 1\n",
    "    return out_x, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data_prep(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 28, 28, 1)\n",
      "(70000, 10)\n"
     ]
    }
   ],
   "source": [
    "#print the response variable dimension\n",
    "print( x.shape, y.shape, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting: train -> 80% and test -> 20%\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x, y, test_size = 0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hold of the current run\n",
    "run = Run.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a CNN model with 5x5 Conv2D w/ ReLU(32 filters), 2x2 MaxPool2D, 5x5 Conv2D w/ ReLU(16 filters), 2x2 MaxPool2D, F.C. w/ ReLU(128), F.C. w/ Softmax (10)\n",
      "Train on 44800 samples, validate on 11200 samples\n",
      "Epoch 1/4\n",
      "44800/44800 [==============================] - 28s 636us/step - loss: 0.2423 - accuracy: 0.9292 - val_loss: 0.0765 - val_accuracy: 0.9765\n",
      "Epoch 2/4\n",
      "44800/44800 [==============================] - 28s 633us/step - loss: 0.0651 - accuracy: 0.9799 - val_loss: 0.0569 - val_accuracy: 0.9817\n",
      "Epoch 3/4\n",
      "44800/44800 [==============================] - 28s 635us/step - loss: 0.0449 - accuracy: 0.9858 - val_loss: 0.0400 - val_accuracy: 0.9870\n",
      "Epoch 4/4\n",
      "44800/44800 [==============================] - 29s 650us/step - loss: 0.0353 - accuracy: 0.9891 - val_loss: 0.0381 - val_accuracy: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f68a5df7208>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train a CNN model with 5x5 Conv2D w/ ReLU(32 filters), 2x2 MaxPool2D, 5x5 Conv2D w/ ReLU(16 filters), 2x2 MaxPool2D, F.C. w/ ReLU(128), F.C. w/ Softmax (10)\")\n",
    "six_layers_CNN_model = models.Sequential()\n",
    "six_layers_CNN_model.add(layers.Conv2D(32, kernel_size=(4,4), padding='Same',\n",
    "                         activation='relu',\n",
    "                         input_shape=(img_rows, img_cols, 1))) # first layer need to specify input shape\n",
    "six_layers_CNN_model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "six_layers_CNN_model.add(layers.Conv2D(16, kernel_size=(4,4), padding='Same', activation='relu'))\n",
    "six_layers_CNN_model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "six_layers_CNN_model.add(layers.Flatten())\n",
    "six_layers_CNN_model.add(layers.Dense(128, activation='relu'))\n",
    "six_layers_CNN_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "six_layers_CNN_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                             optimizer='adam',\n",
    "                             metrics=['accuracy'])\n",
    "six_layers_CNN_model.fit(X_train, Y_train,\n",
    "                         batch_size=100,\n",
    "                         epochs=4,\n",
    "                         validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a CNN model w/ 8 layers: 1 & 2: 4x4 32f Conv2D w/ relu, 3: 2x2 MaxPool, 4 & 5: 4x4 64f Conv2D w/ relu, 6: 2x2 MaxPool with 2x2 stride, 7: 256 F.C. w/ relu, 8: 10 F.C. w/ softmax\n",
      "Train on 44800 samples, validate on 11200 samples\n",
      "Epoch 1/4\n",
      "44800/44800 [==============================] - 148s 3ms/step - loss: 0.2463 - accuracy: 0.9230 - val_loss: 0.0477 - val_accuracy: 0.9845\n",
      "Epoch 2/4\n",
      "44800/44800 [==============================] - 149s 3ms/step - loss: 0.0716 - accuracy: 0.9776 - val_loss: 0.0304 - val_accuracy: 0.9907\n",
      "Epoch 3/4\n",
      "44800/44800 [==============================] - 149s 3ms/step - loss: 0.0485 - accuracy: 0.9852 - val_loss: 0.0272 - val_accuracy: 0.9913\n",
      "Epoch 4/4\n",
      "44800/44800 [==============================] - 148s 3ms/step - loss: 0.0434 - accuracy: 0.9873 - val_loss: 0.0236 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f67bae9c358>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train a CNN model w/ 8 layers: 1 & 2: 4x4 32f Conv2D w/ relu, 3: 2x2 MaxPool, 4 & 5: 4x4 64f Conv2D w/ relu, 6: 2x2 MaxPool with 2x2 stride, 7: 256 F.C. w/ relu, 8: 10 F.C. w/ softmax')\n",
    "eight_layers_model = models.Sequential()\n",
    "eight_layers_model.add(layers.Conv2D(32, kernel_size=(4,4),padding='Same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "eight_layers_model.add(layers.Conv2D(32, kernel_size=(4,4),padding='Same',\n",
    "                 activation='relu'))\n",
    "eight_layers_model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "eight_layers_model.add(layers.Dropout(rate=0.25))\n",
    "eight_layers_model.add(layers.Conv2D(64, kernel_size = (4,4),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "eight_layers_model.add(layers.Conv2D(64, kernel_size = (4,4),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "eight_layers_model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "eight_layers_model.add(layers.Dropout(rate=0.25))\n",
    "eight_layers_model.add(layers.Flatten())\n",
    "eight_layers_model.add(layers.Dense(256, activation = \"relu\"))\n",
    "eight_layers_model.add(layers.Dropout(rate=0.5))\n",
    "eight_layers_model.add(layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "eight_layers_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                     optimizer='adam',\n",
    "                     metrics=['accuracy'])\n",
    "eight_layers_model.fit(X_train, Y_train,\n",
    "                       batch_size=100,\n",
    "                       epochs=4,\n",
    "                       validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test data: X_val\n",
    "Y_pred = eight_layers_model.predict(X_val,\n",
    "                                    batch_size=100,\n",
    "                                    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the indix with the maximum probability\n",
    "Y_pred = Y_pred.argmax(axis = 1)\n",
    "Y_pred = pd.Series(Y_pred,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the actual labels\n",
    "Y_true = Y_val.argmax(axis = 1)\n",
    "Y_true = pd.Series(Y_true,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1420,    0,    0,    0,    0,    0,    7,    0,    1,    0],\n",
       "       [   0, 1579,    8,    0,    0,    0,    1,    3,    0,    0],\n",
       "       [   0,    1, 1370,    0,    0,    0,    0,    1,    3,    2],\n",
       "       [   0,    0,    5, 1414,    0,    4,    0,    2,    1,    3],\n",
       "       [   0,    3,    1,    0, 1351,    0,    0,    1,    0,    4],\n",
       "       [   1,    0,    1,    5,    0, 1268,    3,    0,    3,    0],\n",
       "       [   2,    2,    0,    0,    0,    0, 1333,    0,    3,    0],\n",
       "       [   0,    0,    7,    1,    2,    0,    0, 1433,    0,    3],\n",
       "       [   1,    2,    2,    1,    3,    2,    3,    0, 1402,    2],\n",
       "       [   1,    1,    1,    5,    5,    3,    0,    6,    0, 1308]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9912857142857143\n",
      "Attempted to log scalar metric accuracy:\n",
      "0.9912857142857143\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy on the prediction\n",
    "acc = np.average(Y_pred == Y_true)\n",
    "print('Accuracy is', acc)\n",
    "run.log('accuracy', np.float(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best performance model as an ONNX instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't import tf2onnx module, so the conversion on a model with any custom/lambda layer will fail!\n",
      "WARNING - Can't import tf2onnx module, so the conversion on a model with any custom/lambda layer will fail!\n"
     ]
    }
   ],
   "source": [
    "import onnxmltools\n",
    "\n",
    "onnx_model = onnxmltools.convert_keras(eight_layers_model) \n",
    "\n",
    "onnxmltools.utils.save_model(onnx_model, 'keras_mnist.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model onnxmodelimage\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = \"keras_mnist.onnx\",\n",
    "                       model_name = \"onnxmodelimage\",\n",
    "                       tags = {'area': \"digits_recognition\", 'type': \"CNN\"},\n",
    "                       description = \"Convolutional Neural Network model to recognize digits from ONNX\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnxmodelimage\tConvolutional Neural Network model to recognize digits from ONNX\t1\n"
     ]
    }
   ],
   "source": [
    "print(model.name, model.description, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(workspace=Workspace.create(name='digits_recognition', subscription_id='de98789c-7b3d-4142-8cc3-88bf848066bb', resource_group='machinelearning'), name=onnxmodelimage, id=onnxmodelimage:1, version=1, tags={'area': 'digits_recognition', 'type': 'CNN'}, properties={})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.list(workspace=ws, tags=['area'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
