{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create score.py script: running script for model web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from azureml.core.model import Model\n",
    "import json\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import keras\n",
    "import onnxruntime\n",
    "import base64\n",
    "\n",
    "def init():\n",
    "    global model_path, session, input_name, output_name\n",
    "    model_path = Model.get_model_path(model_name=\"onnxmodelimage\")\n",
    "    session = onnxruntime.InferenceSession(model_path)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "\n",
    "# This method preprocess input image: image -> grayscale -> blur -> threshold -> edges -> dilate \n",
    "# in order to make it ready to be passed to model for prediction\n",
    "def preprocess(image):\n",
    "    global thresh, contours\n",
    "    # resize original image to be fixed size 640 x 480\n",
    "    image = cv.resize(image, (640, 480))\n",
    "    # convert image to gray scale of pixel value from 0 to 255\n",
    "    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    # apply gaussian blur to filter image\n",
    "    blur = cv.GaussianBlur(gray,(5,5),0)\n",
    "    # apply threshold on blurred image to amplify digits\n",
    "    ret,thresh = cv.threshold(blur, 120, 200, cv.THRESH_BINARY_INV)    \n",
    "    # find digits edges using Canny Edge Detection\n",
    "    edges = cv.Canny(thresh, 120, 200)\n",
    "    # apply dilation on detected edges\n",
    "    kernel = np.ones((4,4),np.uint8)\n",
    "    dilate = cv.dilate(edges, kernel)\n",
    "    \n",
    "    # find contours and get the external one\n",
    "    im2, contours, hierarchy = cv.findContours(dilate, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# This method find the bounding box for each digit in the image based on contours\n",
    "def findBoundingBoxes():\n",
    "    rect = []\n",
    "    # with each contour, draw boundingRect in blue\n",
    "    for c in contours:\n",
    "        # get the bounding rect\n",
    "        x, y, w, h = cv.boundingRect(c)\n",
    "        rect.append([x, y, w, h])\n",
    "    return rect\n",
    "\n",
    "# This method merge bounding boxes for same digit\n",
    "# and sort each box by x-axis value\n",
    "def mergeBoundingBoxes(rect):\n",
    "    rect = np.array(rect)\n",
    "    for i in range(len(rect)):\n",
    "        j = i + 1\n",
    "        while j < len(rect):\n",
    "            # check if rect[j] is within rect[i]\n",
    "            xBound = rect[j][0] > rect[i][0] and rect[j][0]+rect[j][2] < rect[i][0]+rect[i][2]\n",
    "            yBound = rect[j][1] > rect[i][1] and rect[j][1]+rect[j][3] < rect[i][1]+rect[i][3]\n",
    "            if (xBound and yBound) == True:\n",
    "                rect = np.delete(rect, j, 0)\n",
    "                j = i + 1\n",
    "            else:\n",
    "                j = j + 1\n",
    "    # sort bounding boxes on x-axis value\n",
    "    groupedRect = rect[rect[:,0].argsort()].tolist()\n",
    "    return groupedRect\n",
    "\n",
    "# This method iterate thorugh bounding boxes and extract for ROI\n",
    "def extractROI(rect):\n",
    "    digits = []\n",
    "    original = thresh.copy()\n",
    "    image_number = 0\n",
    "    for pts in rect:\n",
    "        # add border to each digit\n",
    "        ROI = original[pts[1]-10:pts[1]+pts[3]+10, pts[0]-10:pts[0]+pts[2]+10]\n",
    "        digits.append(ROI)\n",
    "        # cv.imwrite(\"ROI_{}.png\".format(image_number), ROI)\n",
    "        image_number += 1\n",
    "    return digits\n",
    "\n",
    "# This method resize each digit image to be 28 x 28 and normalize its values to be between 0 to 1\n",
    "def resizeAndNormalize(digits):\n",
    "    input_data = []\n",
    "    for digit in digits:\n",
    "        digit = cv.resize(digit, (28,28))\n",
    "        digit = np.divide(digit, 255)\n",
    "        input_data.append(digit)\n",
    "    return input_data\n",
    "        \n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "    img_cols = 28\n",
    "    img_rows = 28\n",
    "    try:\n",
    "        #with open(raw_data) as json_file:\n",
    "        #    data = json.load(json_file)\n",
    "        \n",
    "        # convert JSON format img str to bytes and decode back to img file\n",
    "        json_to_bytes = json.loads(raw_data).encode('utf-8')\n",
    "        decoded_img = base64.decodebytes(json_to_bytes)\n",
    "        image = cv.imdecode(np.asarray(bytearray(decoded_img), dtype=\"uint8\"), cv.IMREAD_COLOR)  \n",
    "        \n",
    "        #image_name = 'imgToPred.jpg'\n",
    "        #with open(image_name, 'wb') as image_result:\n",
    "        #    image_result.write(decoded_img)        \n",
    "        #image_path = os.path.join(os.getcwd(), image_name)\n",
    "        \n",
    "        preprocess(image)\n",
    "        rect = findBoundingBoxes()\n",
    "        groupedRect = mergeBoundingBoxes(rect)\n",
    "        digits = extractROI(groupedRect)\n",
    "        input_data = resizeAndNormalize(digits)\n",
    "        \n",
    "        input_data = np.array(input_data).astype('float32')\n",
    "        input_data = input_data.reshape(input_data.shape[0], img_rows, img_cols, 1)\n",
    "        r = session.run([output_name], {input_name: input_data})\n",
    "        for row in r: # select the indix with the maximum probability\n",
    "            result = pd.Series(np.array(row).argmax(axis=1), name=\"Label\")\n",
    "        output = io.StringIO()\n",
    "        json.dump(result.tolist(), output)\n",
    "        return output.getvalue()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create .yml containing all dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Create the environment\n",
    "myenv = CondaDependencies.create(pip_packages=['onnxruntime','azureml-core','keras',\"azureml-defaults\"],\n",
    "                                 conda_packages=['python=3.6.9','tensorflow=2.0.0','pandas=0.23.4','numpy=1.16.2','mesa-libgl-cos6-x86_64','opencv=3.4.2'])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(runtime= \"python\", \n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"myenv.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azureml.core import Workspace\n",
    "# load workspace configuration from the config.json file in the config folder.\n",
    "ws = Workspace.from_config(path='jingjing.dong.mil/config/config.json')\n",
    "print(ws.name, ws.location, ws.resource_group, sep='\\t')\n",
    "compute_target = ws.compute_targets['cpucluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  description = \"digits_image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Azure Container Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = \"keras_mnist.onnx\",\n",
    "                       model_name = \"onnxmodelimage\",\n",
    "                       tags = {'area': \"digits_recognition\", 'type': \"CNN\"},\n",
    "                       description = \"Convolutional Neural Network model to recognize digits from ONNX\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model.list(workspace=ws, tags=['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image = ContainerImage.create(name = \"onnxmodelimage\",\n",
    "                              models = [model],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the image as a web service on Azure Containter Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               description = 'ONNX for mnist model with preprocess') \n",
    "service_name = 'handwritten-digits-recog-3'\n",
    "service = Webservice.deploy_from_image(deployment_config = aciconfig, \n",
    "                                       image = image,\n",
    "                                       name = service_name,\n",
    "                                       workspace = ws)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "service.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Web Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "\n",
    "image_path = os.path.join(os.getcwd(), 'test_images/IMG_7525.jpg')\n",
    "with open(image_path, 'rb') as file:\n",
    "    img = file.read()\n",
    "image_64_encode = base64.encodebytes(img).decode('utf-8')\n",
    "bytes_to_json = json.dumps(image_64_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 8, 7, 2, 9, 4]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "scoring_url = 'http://a5443bf0-eff3-47ee-8692-f304ddca0ae0.centralus.azurecontainer.io/score'\n",
    "headers = { 'Content-Type': 'application/json' }\n",
    "response = requests.post(scoring_url, bytes_to_json, headers=headers)\n",
    "print(json.loads(response.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
