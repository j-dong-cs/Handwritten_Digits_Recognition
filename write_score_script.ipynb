{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create score.py script: running script for model web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from azureml.core.model import Model\n",
    "import json\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import keras\n",
    "import onnxruntime\n",
    "\n",
    "def init():\n",
    "    global model_path, session, input_name, output_name\n",
    "    model_path = Model.get_model_path(model_name=\"onnxmodelimage\")\n",
    "    session = onnxruntime.InferenceSession(model_path)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "        \n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "    global image\n",
    "    img_cols = 28\n",
    "    img_rows = 28\n",
    "    try:\n",
    "        #with open(raw_data) as json_file:\n",
    "        #    data = json.load(json_file)\n",
    "        \n",
    "        # convert JSON format img str to bytes and decode back to img file\n",
    "        json_to_bytes = json.loads(raw_data).encode('utf-8')\n",
    "        decoded_img = base64.decodebytes(json_to_bytes)\n",
    "        image = cv.imdecode(np.asarray(bytearray(decoded_img), dtype=\"uint8\"), cv.IMREAD_COLOR) \n",
    "        #image_name = 'imgToPred.jpg'\n",
    "        #with open(image_name, 'wb') as image_result:\n",
    "        #    image_result.write(decoded_img)        \n",
    "        #image_path = os.path.join(os.getcwd(), image_name)\n",
    "        \n",
    "        preprocess()\n",
    "        findBoundingBoxes()\n",
    "        mergeBoundingBoxes()\n",
    "        extractROI()\n",
    "        resizeAndNormalize()\n",
    "        \n",
    "        input_data = np.array(input_data).astype('float32')\n",
    "        input_data = input_data.reshape(input_data.shape[0], img_rows, img_cols, 1)\n",
    "        r = session.run([output_name], {input_name: input_data})\n",
    "        for row in r: # select the indix with the maximum probability\n",
    "            result = pd.Series(np.array(row).argmax(axis=1), name=\"Label\")\n",
    "        output = io.StringIO()\n",
    "        json.dump(result.tolist(), output)\n",
    "        return output.getvalue()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error\n",
    "\n",
    "# This method preprocess input image: image -> grayscale -> blur -> threshold -> edges -> dilate \n",
    "# in order to make it ready to be passed to model for prediction\n",
    "def preprocess():\n",
    "    global gray, blur, thresh, edges, dilate, contours\n",
    "    # img = cv.imread(image_path)\n",
    "    # resize original image to be fixed size 640 x 480\n",
    "    image = cv.resize(image, (640, 480))\n",
    "    # convert image to gray scale of pixel value from 0 to 255\n",
    "    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    # apply gaussian blur to filter image\n",
    "    blur = cv.GaussianBlur(gray,(5,5),0)\n",
    "    # apply threshold on blurred image to amplify digits\n",
    "    ret,thresh = cv.threshold(blur, 120, 200, cv.THRESH_BINARY_INV)    \n",
    "    # find digits edges using Canny Edge Detection\n",
    "    edges = cv.Canny(thresh, 120, 200)\n",
    "    # apply dilation on detected edges\n",
    "    kernel = np.ones((4,4),np.uint8)\n",
    "    dilate = cv.dilate(edges, kernel)\n",
    "    \n",
    "    # find contours and get the external one\n",
    "    contours, hier = cv.findContours(dilate, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# This method find the bounding box for each digit in the image based on contours\n",
    "def findBoundingBoxes():\n",
    "    global rect\n",
    "    rect = []\n",
    "    # with each contour, draw boundingRect in blue\n",
    "    for c in contours:\n",
    "        # get the bounding rect\n",
    "        x, y, w, h = cv.boundingRect(c)\n",
    "        rect.append([x, y, w, h])\n",
    "\n",
    "# This method merge bounding boxes for same digit\n",
    "# and sort each box by x-axis value\n",
    "def mergeBoundingBoxes():\n",
    "    for i in range(len(rect)):\n",
    "        j = i + 1\n",
    "        while j < len(rect):\n",
    "            # check if rect[j] is within rect[i]\n",
    "            xBound = rect[j][0] > rect[i][0] and rect[j][0]+rect[j][2] < rect[i][0]+rect[i][2]\n",
    "            yBound = rect[j][1] > rect[i][1] and rect[j][1]+rect[j][3] < rect[i][1]+rect[i][3]\n",
    "            if (xBound and yBound) == True:\n",
    "                rect = np.delete(rect, j, 0)\n",
    "                j = i + 1\n",
    "            else:\n",
    "                j = j + 1\n",
    "    # sort bounding boxes on x-axis value\n",
    "    rect = rect[rect[:,0].argsort()]\n",
    "\n",
    "# This method iterate thorugh bounding boxes and extract for ROI\n",
    "def extractROI():\n",
    "    global digits\n",
    "    digits = []\n",
    "    original = thresh.copy()\n",
    "    image_number = 0\n",
    "    for rect in groupedRect:\n",
    "        ROI = original[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
    "        digits.append(ROI)\n",
    "        # cv.imwrite(\"ROI_{}.png\".format(image_number), ROI)\n",
    "        image_number += 1\n",
    "\n",
    "# This method resize each digit image to be 28 x 28 and normalize its values to be between 0 to 1\n",
    "def resizeAndNormalize():\n",
    "    global input_data\n",
    "    input_data = []\n",
    "    for digit in digits:\n",
    "        digit = cv.resize(digit, (28,28))\n",
    "        digit = np.divide(digit, 255)\n",
    "        input_data.append(digit.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create .yml containing all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Create the environment\n",
    "myenv = CondaDependencies.create(pip_packages=[\"numpy\",\"onnxruntime\",\"azureml-core\",\"keras\",\"pandas\",\"azureml-defaults\",\"tensorflow\",\"cv2\"])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(runtime= \"python\", \n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"myenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  description = \"digits_image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Azure Container Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ContainerImage.create(name = \"onnxmodelimage\",\n",
    "                              models = [model],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the image as a web service on Azure Containter Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               description = 'ONNX for mnist model') \n",
    "service_name = 'keras-mnist-classification'\n",
    "service = Webservice.deploy_from_image(deployment_config = aciconfig, \n",
    "                                       image = image,\n",
    "                                       name = service_name,\n",
    "                                       workspace = ws)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
